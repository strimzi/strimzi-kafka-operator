# TMT test plan definition
# https://tmt.readthedocs.io/en/latest/overview.html

# Baseline common for all test plans
#######################################################################
summary: Strimzi test suite
discover:
  how: fmf

# Required HW
provision:
  hardware:
    memory: ">= 24 GiB"
    cpu:
      processors: ">= 8"

# Install required packages and scripts for running strimzi suite
prepare:
  - name: Clean cache
    how : shell
    script: |
        OS=$(cat /etc/redhat-release || true)
        if [[ ${OS} == *"CentOS"* ]]; then
            sudo yum -y clean dbcache
        else
            sudo dnf -y clean dbcache
        fi

  - name: Install packages
    how: install
    package:
      - wget
      - java-17-openjdk-devel
      - xz
      - make
      - git
      - zip
      - coreutils

  - name: Install docker-ce
    how: shell
    script: |
      OS=$(cat /etc/redhat-release || true)
      if [[ ${OS} == *"CentOS"* ]]; then
        sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
      else
        sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo
      fi

      sudo yum install -y docker-ce
      sudo systemctl enable docker --now

  - name: Install yq
    how: shell
    script: |
      ARCH=$(uname -m)
      if [[ $ARCH == "x86_64" ]]; then ARCH="amd64"; fi
      if [[ $ARCH == "aarch64" ]]; then ARCH="arm64"; fi
      ./.azure/scripts/install_yq.sh ${ARCH}

  - name: Install oc kubectl client
    how: shell
    script: |
      PLATFORM=$(uname -m)
      URL="http://mirror.openshift.com/pub/openshift-v4/${PLATFORM}/clients/ocp/stable/openshift-client-linux.tar.gz"
      mkdir -p /tmp/openshift
      wget ${URL} -O openshift.tar.gz -q
      tar xzf openshift.tar.gz -C /tmp/openshift
      sudo cp /tmp/openshift/oc /usr/bin/oc
      sudo cp /tmp/openshift/kubectl /usr/bin/kubectl
      sudo rm -rf /tmp/openshift/
      sudo rm -rf openshift.tar.gz

  - name: Install mvn
    how: shell
    script: |
      mkdir -p /usr/share/maven /usr/share/maven/ref
      curl -fsSL -o /tmp/apache-maven.tar.gz https://apache.osuosl.org/maven/maven-3/3.8.8/binaries/apache-maven-3.8.8-bin.tar.gz
      tar -xzf /tmp/apache-maven.tar.gz -C /usr/share/maven --strip-components=1
      rm -f /tmp/apache-maven.tar.gz
      ln -s /usr/share/maven/bin/mvn /usr/bin/mvn

  - name: Install kind
    how: shell
    script: |
      ARCH=$(uname -m)
      if [[ $ARCH == "x86_64" ]]; then ARCH="amd64"; fi
      if [[ $ARCH == "aarch64" ]]; then ARCH="arm64"; fi
      ./.azure/scripts/setup-kind.sh ${ARCH}

  - name: Install helm
    how: shell
    script: |
      ./.azure/scripts/setup-helm.sh

  - name: Install shellcheck
    how: shell
    script: |
      ./.azure/scripts/setup_shellcheck.sh

  - name: Build strimzi images
    how: shell
    script: |
      # build images
      ARCH=$(uname -m)
      if [[ ${ARCH} == "aarch64" ]]; then
        export DOCKER_BUILD_ARGS="--platform linux/arm64 --build-arg TARGETPLATFORM=linux/arm64"
      fi
      #
      HOST=""
      if [[ ${IP_FAMILY} == "ipv4" || ${IP_FAMILY} == "dual" ]]; then
        HOST=$(hostname --ip-address | grep -oE '\b([0-9]{1,3}\.){3}[0-9]{1,3}\b' | awk '$1 != "127.0.0.1" { print $1 }' | head -1)
      elif [[ ${IP_FAMILY} == "ipv6" ]]; then
        HOST="myregistry.local"
      fi
      export MVN_ARGS="-B -DskipTests -Dmaven.javadoc.skip=true --no-transfer-progress"

      # Setup local registry for building images and connect image
      export DOCKER_REGISTRY="${HOST}:5001"
      export DOCKER_ORG="strimzi"
      export DOCKER_TAG="latest"

      make java_install

      # Build images only for non-release triggers
      if [[ ${RELEASE:-False} != True ]]; then
        make docker_build
        make docker_tag
        make docker_push
      fi

      # Get latest Kafka version from kafka-versions.yaml
      export KAFKA_VERSION=$(cat kafka-versions.yaml | yq eval '.[] | select(.default) | .version' -)
      # Set env var for KafkaConnect build image to avoid building images
      export CONNECT_IMAGE_WITH_FILE_SINK_PLUGIN="${DOCKER_REGISTRY}/${DOCKER_ORG}/connect-file-sink:latest"
      # Build base image from previous data
      # Set quay and release tag in case the pipeline is triggered by release
      if [[ ${RELEASE} == True ]]; then
        export BASE_IMAGE="quay.io/strimzi/kafka:${PACKIT_TAG_NAME}-kafka-KAFKA_VERSION"
      else
        export BASE_IMAGE="${DOCKER_REGISTRY}/${DOCKER_ORG}/kafka:${DOCKER_TAG}-kafka-KAFKA_VERSION"
      fi

      # Build the connect image
      eval $(./systemtest/src/test/resources/connect-build/build-connect-image.sh "$KAFKA_VERSION" "$BASE_IMAGE" "$CONNECT_IMAGE_WITH_FILE_SINK_PLUGIN")
      docker push $CONNECT_IMAGE_WITH_FILE_SINK_PLUGIN

# Discover tmt defined tests in tests/ folder
execute:
  how: tmt

# Post install step to copy logs
finish:
  how: shell
  script: ./systemtest/tmt/scripts/copy-logs.sh
#######################################################################

/smoke:
  summary: Run smoke strimzi test suite with kraft
  provision:
    hardware:
      memory: ">= 12 GiB"
      cpu:
        processors: ">= 4"
  discover+:
    test:
      - smoke

/regression-operators:
  summary: Run regression strimzi test suite with kraft
  discover+:
    test:
      - regression-operators

/regression-brokers-and-security:
  summary: Run regression strimzi test suite with kraft
  discover+:
    test:
      - regression-brokers-and-security

/regression-operands:
  summary: Run regression strimzi test suite with kraft
  discover+:
    test:
      - regression-operands

/acceptance:
  summary: Run acceptance strimzi test suite with kraft
  provision:
    hardware:
      memory: ">= 24 GiB"
      cpu:
        processors: ">= 8"
  discover+:
    test:
      - acceptance

/sanity:
  summary: Run sanity strimzi test suite with kraft
  provision:
    hardware:
      memory: ">= 16 GiB"
      cpu:
        processors: ">= 4"
  discover+:
    test:
      - sanity

/upgrade:
  summary: Run upgrade strimzi test suite with kraft
  provision:
    hardware:
      memory: ">= 12 GiB"
      cpu:
        processors: ">= 4"
  discover+:
    test:
      - upgrade

/performance:
  summary: Run performance test suite with kraft
  discover+:
    test:
      - performance

/user-capacity:
  summary: Run performance user operator capacity test suite with kraft
  provision:
    hardware:
      memory: ">= 30 GiB"
      cpu:
        processors: ">= 8"
      # it seems that default disk size (i.e., 50GB) is not enough for user operator capacity tests
      disk:
        - size: ">= 60 GB"
  discover+:
    test:
      - user-capacity

/topic-capacity:
  summary: Run performance topic operator capacity test suite with kraft
  provision:
    hardware:
      memory: ">= 30 GiB"
      cpu:
        processors: ">= 8"
      # it seems that default disk size (i.e., 50GB) is not enough for topic operator capacity tests
      disk:
        - size: ">= 60 GB"
  discover+:
    test:
      - topic-capacity
