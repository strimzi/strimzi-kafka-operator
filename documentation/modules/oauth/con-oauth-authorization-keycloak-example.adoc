// Module included in the following module:
//
// con-oauth-authorization-keycloak-authorization-services.adoc

[id='con-oauth-authorization-keycloak-example_{context}']
= Example authorization rules configuration using Authorization Services

This is an end-to-end example of using {keycloak-project-name} Authorization Services to configure authorization rules for use with `keycloak` authorization in {strimzi-project-name} Operator.
The example starts by deploying the {keycloak-project-name} server with a pre-configured realm, requiring no additional configuration.
We deploy the Kafka cluster configured to use the pre-configured realm.
We then connect to the {keycloak-project-name} Admin Console and demonstrate the sections of the user interface where authorization rules are configured.
We use Kafka CLI client tools with different personal and service accounts to demonstrate limited access based on the permissions granted to different accounts.

[CAUTION]
====
This example is focused on explaining how to use {keycloak-project-name} Authorization Services.
While TLS connectivity is used where necessary, the server certificates are autogenerated, and TLS termination for {keycloak-project-name} server is on a reverse proxy server using an {ingress}, not on {keycloak-project-name} server pod. Additional care should be taken and review done when creating the production configuration.
Also note, that {keycloak-project-name} requires that Kafka clients use the exact same hostname and port as the Kafka brokers. This example assumes that the {ingress} hostname is visible to pods inside the {kubernetes} cluster, which may not be the case on your {kubernetes} cluster (for example, it may be visible to Kafka clients outside the {kubernetes} cluster, but not from the pods inside the cluster).
====

== Token-based authorization with {keycloak-project-name} Authorization Services

When using {keycloak-project-name} with `oauth` authentication, the access token is available, and it is then possible to use centrally managed authorization rules to enforce access restrictions onto Kafka Clients.
{strimzi-project-name} Operator comes with support for {keycloak-project-name} Authorization Services in the form of `keycloak` authorization, which allows using {keycloak-project-name} to manage fine grained permissions to Kafka resources.

When using `keycloak` authorization, a custom authorizer is configured on the Kafka broker that uses Authorization Services REST endpoints available on {keycloak-project-name}, which provide a list of granted permissions on resources for authenticated users.
The list of grants (permissions) is fetched as the first action after an authenticated session is established by the Kafka client, and then regularly refreshed in the background.
Grants are cached and enforced locally on the Kafka broker for each user session to provide fast authorization decisions. Because they are periodically refreshed, any changes to the grants on the {keycloak-project-name} server are detected and enforced.

== Provisioning the {keycloak-project-name} server

The easiest way to install the {keycloak-project-name} server is to use the {keycloak-project-name} Operator. Follow the instructions in {keycloak-server-install-doc}.

== Uploading the demo realm

Once a {keycloak-project-name} instance is running, we can upload the example realm by using the {keycloak-project-name} Admin Console

The following instructions can be used regardless of how your {keycloak-project-name} instance was provisioned. If {keycloak-project-name} Operator was used, then you can follow the steps to obtain the necessary information to continue, otherwise you may have to discover the necessary information for the next steps yourself.

First, determine the external hostname to access the Admin Console.

For example, if the {keycloak-project-name} Operator was used to install {keycloak-project-name} server in project (namespace) called `sso`, you can run:

[source,shell,subs="attributes"]
----
NS=sso
{kubectl} get {ingress} keycloak -n $NS
----

Second, determine the password for the admin user.

If you used {keycloak-project-name} Operator, the password is stored as a secret, so you first have to identify the name of the secret. You can inspect the yaml for the {keycloak-project-name} instance. For example:

[source,shell,subs="attributes"]
----
{kubectl} get -n $NS pod keycloak-0 -o yaml | less
----

Search for `KEYCLOAK_PASSWORD`, and note the `secretKeyRef`.`name`. It is usually something like `credential-keycloak`.

You can then obtain the clear text password by running:

[source,shell,subs="attributes"]
----
SECRET_NAME=credential-keycloak
{kubectl} get -n $NS secret $SECRET_NAME -o yaml | grep PASSWORD | awk '{print $2}' | base64 -D
----

Now, login to the Admin Console (you have to use https://HOST for {kubernetes} {ingress}) using `admin` as the username, and the revealed password.

Once logged in, use `Add Realm` to import the example realm. Select `$EXAMPLES_DIR/security/keycloak/kafka-authz-realm.json` file from your disk, and click `Create`.

You should now have `kafka-authz` as your current realm in the Admin Console.

== Deploying the minimal Kafka cluster

We assume that the {strimzi-project-name} Cluster Operator has already been installed on the {kubernetes}  cluster.

Our Kafka cluster has to be properly configured with authentication and authorization settings to connect to our {keycloak-project-name} instance.

Assuming the {keycloak-project-name} Operator was used to install the {keycloak-project-name} server instance, and that `sso` namespace (project) was used, we can determine the external hostname:

[source,shell,subs="attributes"]
----
NS=sso
{kubectl} get {ingress} keycloak -n $NS
----

{kubernetes} {ingress} uses a secure connection (https) which means that we need to prepare a certificate truststore to make it possible for Kafka brokers to speak to the {keycloak-project-name} server.

[source,shell]
----
SSO_HOST=<sso_hostname>
SSO_HOST_PORT=$SSO_HOST:443
STOREPASS=storepass

echo "Q" | openssl s_client -showcerts -connect $SSO_HOST_PORT 2>/dev/null | awk ' /BEGIN CERTIFICATE/,/END CERTIFICATE/ { print $0 } ' > /tmp/sso.crt
----

Now we need to deploy the certificate to {kubernetes} as a secret:

[source,shell,subs="attributes"]
----
{kubectl} create secret generic oauth-server-cert --from-file=/tmp/sso.crt -n $NS
----

Set the hostname as an ENV var before deploying the prepared `Kafka` custom resource for the example:

[source,shell,subs="attributes"]
----
SSO_HOST=&lt;sso_hostname&gt;
EXAMPLES_DIR=examples
cat $EXAMPLES_DIR/kafka/kafka-ephemeral-oauth-single-keycloak-authz.yaml | sed -E 's#\${SSO_HOST}'"#$SSO_HOST#" | {kubectl} create -n $NS -f -
----


== Using the {keycloak-project-name} Admin Console to configure authorization

When logging into the Admin Console, the default view displays the *Master* realm.
For this example we are interested in the `kafka-authz` realm, which you can select in the upper left corner.

Initially, the *Realm Settings* section is selected, but you can navigate to  *Groups*, *Roles*, *Clients* and *Users*.

Under *Groups*, you can view groups to mark users as having some permissions.
Groups are sets of users with a name assigned. Typically, they are used to compartmentalize users into geographical, organizational or departmental units.

In {keycloak-project-name}, groups can be stored in an LDAP identity provider.
That makes it possible to make a user a member of a group through a custom LDAP server admin user interface, for example, to grant them some permissions on Kafka resources.

Under *Users*, you can view all defined users. For this example, `alice` and `bob` are defined. `alice` is a member of the `ClusterManager Group`, and `bob` is a member of `ClusterManager-my-cluster Group`.
In {keycloak-project-name}, users can be stored in an LDAP identity provider.

Under *Roles*, you can view the realm roles to mark users or clients as having some permissions.
Roles are a concept analogous to groups. They are usually used to _tag_ users with organizational roles and have the requisite permissions.
Roles cannot be stored in an LDAP identity provider.
If LDAP is a requirement, you can use groups instead, and add {keycloak-project-name} roles to the groups so that when users are assigned a group, they also get a corresponding role.

Under *Clients*, you can view the additional client configurations. For this example,  `kafka`, `kafka-cli`, `team-a-client`, `team-b-client` are configured.
The client with client id `kafka` is used by Kafka Brokers to perform the necessary OAuth 2.0 communication for access token validation,
and to authenticate to other Kafka Broker instances using OAuth 2.0 client authentication.
This client also contains the Authorization Services resource definitions, policies and authorization scopes used to perform authorization on the Kafka Brokers.

The client with client id `kafka-cli` is a public client that can be used by the Kafka command line tools when authenticating with username and password to obtain an access token or a refresh token.

Clients `team-a-client`, and `team-b-client` are confidential clients representing services with partial access to certain Kafka topics.

The authorization configuration is defined in the `kafka` client from the *Authorization* tab, which becomes visible when *Authorization Enabled* is switched on from the *Settings* tab.


== Defining Authorization Services for access control

{keycloak-project-name} Authorization Services use authorization scopes, policies and permissions to define and apply access control to resources, as explained in {authz-services-model-ref}.

From *Authorization* / *Permissions* you can see the granted permissions that use resources and policies defined from other *Resources* and *Policies* tabs. For example, the `kafka` client has the following permissions:
----
Dev Team A can write to topics that start with x_ on any cluster
Dev Team B can read from topics that start with x_ on any cluster
Dev Team B can update consumer group offsets that start with x_ on any cluster
ClusterManager of my-cluster Group has full access to cluster config on my-cluster
ClusterManager of my-cluster Group has full access to consumer groups on my-cluster
ClusterManager of my-cluster Group has full access to topics on my-cluster
----

`Dev Team A can write to topics that start with x_ on any cluster` combines a resource called `Topic:x_*`, scopes `Describe` and `Write`, and `Dev Team A` policy. The `Dev Team A` policy matches all users that have a realm role called `Dev Team A`.

`Dev Team B can read from topics that start with x_ on any cluster` combines `Topic:x_*`, and `Group:x_*` resources, scopes `Describe` and `Read`, and `Dev Team B` policy. The `Dev Team A` policy matches all users that have a realm role called `Dev Team B`. Matching users and clients have the ability to read from topics, and update the consumed offsets for topics and consumer groups that have names starting with `x_`.

== Targeting permissions using group or role policies

In {keycloak-project-name}, confidential clients with service accounts enabled can authenticate to the server in their own name using a client ID and a secret.
This is convenient for microservices which typically act in their own name, and not as agents of a particular user (like a web site would, for example).
Service accounts can have roles assigned like regular users.
They cannot, however, have groups assigned.
As a consequence, if you want to target permissions to microservices using service accounts, you cannot use group policies, and should instead use role policies.
Conversely, if you want to limit certain permissions only to regular user accounts where authentication with username and password is required, you can achieve that as a side effect of using the group policies, rather than the role policies.
That is what is used for permissions that start with `ClusterManager`.
Performing cluster management is usually done interactively - in person - using CLI tools.
It makes sense to require the user to log in, before using the resulting access token to authenticate to the Kafka Broker.
In this case, the access token represents the specific user, rather than the client application.


== Authorization in action using CLI clients

Make sure that authorization rules have been properly imported.

From menu:Clients[kafka>Authorization>Settings] make sure that *Decision Strategy* is set to *Affirmative*, and NOT to *Unanimous*.
Navigate in {keycloak-project-name} to check that the expected resources, authorization claims, policies and permissions are defined.

With the configuration in place, we can check access to Kafka by using a producer and consumer to create topics using different user and service accounts.

First, a new interactive pod container is run using a {strimzi-project-name} Kafka image to connect to a running Kafka broker.

[source,shell,subs="attributes"]
----
NS=sso
{kubectl} run -ti --restart=Never --image={DockerKafkaImageCurrent} kafka-cli -n $NS -- /bin/sh
----

NOTE: If `{kubectl}` times out waiting on the image download, subsequent attempts may result in an _AlreadyExists_ error.

You can attach to the existing pod by running:

[source,shell]
----
{kubectl} attach -ti kafka-cli
----

To produce messages as client `team-a-client`, we prepare a Kafka client configuration file.
We use SASL_OAUTHBEARER mechanism with Client ID and Client Secret which means the client will first connect to {keycloak-project-name} server to obtain an access token. Then it will connect to the Kafka broker and use the obtained access token to authenticate.

We need to prepare and configure the truststore for TLS connections to work.

First, we use the external hostname exposing the {keycloak-project-name} to obtain the certificate.

[source,shell]
----
SSO_HOST=<sso_hostname>
SSO_HOST_PORT=$SSO_HOST:443
STOREPASS=storepass

echo "Q" | openssl s_client -showcerts -connect $SSO_HOST_PORT 2>/dev/null | awk ' /BEGIN CERTIFICATE/,/END CERTIFICATE/ { print $0 } ' > /tmp/sso.crt

keytool -keystore /tmp/truststore.p12 -storetype pkcs12 -alias sso -storepass $STOREPASS -import -file /tmp/sso.crt -noprompt
----

Then, we add to the same truststore the certificate for the Kafka broker, which we obtain using the `my-cluster-kafka-bootstrap` as a hostname and `tls` listener port (9093):

[source,shell]
----
KAFKA_HOST_PORT=my-cluster-kafka-bootstrap:9093
STOREPASS=storepass

echo "Q" | openssl s_client -showcerts -connect $KAFKA_HOST_PORT 2>/dev/null | awk ' /BEGIN CERTIFICATE/,/END CERTIFICATE/ { print $0 } ' > /tmp/my-cluster-kafka.crt

keytool -keystore /tmp/truststore.p12 -storetype pkcs12 -alias my-cluster-kafka -storepass $STOREPASS -import -file /tmp/my-cluster-kafka.crt -noprompt
----

Finally, let's prepare the Kafka Client configuration parameters:

[source,shell]
----
SSO_HOST=<sso_hostname>

cat > /tmp/team-a-client.properties << EOF
security.protocol=SASL_SSL
ssl.truststore.location=/tmp/truststore.p12
ssl.truststore.password=$STOREPASS
ssl.truststore.type=PKCS12
sasl.mechanism=OAUTHBEARER
sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
  oauth.client.id="team-a-client" \
  oauth.client.secret="team-a-client-secret" \
  oauth.ssl.truststore.location="/tmp/truststore.p12" \
  oauth.ssl.truststore.password="$STOREPASS" \
  oauth.ssl.truststore.type="PKCS12" \
  oauth.token.endpoint.uri="https://$SSO_HOST/auth/realms/kafka-authz/protocol/openid-connect/token" ;
sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler
EOF
----

The roles assigned to a client, such as the `Dev Team A` realm role assigned to the `team-a-client` service account, are presented in {keycloak-project-name} Admin Console on the *Service Account Roles* tab of *Clients* section.

We can use this configuration from the Kafka CLI to produce and consume messages, and perform other administration tasks.


.Producing messages with authorized access

The `team-a-client` configuration is used to produce messages to topics that start with `a_` or `x_`.
The next command will result in error due to trying to write to topic `my-topic`:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic my-topic \
  --producer.config=/tmp/team-a-client.properties
First message
----

A `Not authorized to access topics: [my-topic]` error is returned when trying to push the first message.

`team-a-client` has a `Dev Team A` role that gives it permission to perform any supported actions on topics that start with `a_`, but can only write to topics that start with `x_`.
The topic named `my-topic` matches neither of those rules.

The `team-a-client` configuration is then used to produce messages to topic `a_messages`:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic a_messages \
  --producer.config /tmp/team-a-client.properties
First message
Second message
----

The messages are pushed out successfully, and in the Kafka container log there is DEBUG level output saying `Authorization GRANTED`.

Use CTRL-C to exit the CLI application.

You can see the Kafka container log by running:

[source,shell,subs="attributes"]
{kubectl} logs my-cluster-kafka-0 -f -n $NS

.Consuming messages with authorized access

The `team-a-client` configuration can be used to consume messages from topic `a_messages`, but the next command will result in error:

[source,shell,subs=+quotes]
----
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic a_messages \
  --from-beginning --consumer.config /tmp/team-a-client.properties
----

An error is returned as the `Dev Team A` role for `team-a-client` only has access to consumer groups that have names starting with `a_`.
The `team-a-client` configuration is then used to consume messages when specifying a custom consumer group with a name that starts with `a_`:

[source,shell,subs=+quotes]
----
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic a_messages \
  --from-beginning --consumer.config /tmp/team-a-client.properties --group a_consumer_group_1
----

This time the consumer receives all the messages from the `a_messages` topic.


.Administering Kafka with authorized access

The `team-a-client` is an account without any cluster-level access, but can still be used with some administrative operations.

Listing topics returns the `a_messages` topic:

[source,shell]
----
bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/team-a-client.properties --list
----

Listing consumer groups returns the `a_consumer_group_1` consumer group:

[source,shell]
----
bin/kafka-consumer-groups.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/team-a-client.properties --list
----

Fetching the default cluster configuration fails cluster authorization, because the operation requires cluster level permissions that `team-a-client` does not have:

[source,shell]
----
bin/kafka-configs.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/team-a-client.properties \
  --entity-type brokers --describe --entity-default
----


.Using clients with different permissions

As with `team-a-client`, we prepare a Kafka client configuration file with authentication parameters for `team-b-client`:

[source,shell]
----
cat > /tmp/team-b-client.properties << EOF
security.protocol=SASL_SSL
ssl.truststore.location=/tmp/truststore.p12
ssl.truststore.password=$STOREPASS
ssl.truststore.type=PKCS12
sasl.mechanism=OAUTHBEARER
sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
  oauth.client.id="team-b-client" \
  oauth.client.secret="team-b-client-secret" \
  oauth.ssl.truststore.location="/tmp/truststore.p12" \
  oauth.ssl.truststore.password="$STOREPASS" \
  oauth.ssl.truststore.type="PKCS12" \
  oauth.token.endpoint.uri="https://$SSO_HOST/auth/realms/kafka-authz/protocol/openid-connect/token" ;
sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler
EOF
----

The `team-b-client` client configuration includes a `Dev Team B` realm role and permissions that start with `Dev Team B ...`. These match the users and service accounts that have the `Dev Team B` realm role assigned to them.
The `Dev Team B` users have full access to topics beginning with `b_` on the Kafka cluster `my-cluster`, the name of the designated cluster, and read access on topics that start with `x_`.

The `team-b-client` configuration is used to produce messages to topics that start with `b_`. Writing to topic `a_messages` will result in error:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic a_messages \
  --producer.config /tmp/team-b-client.properties
Message 1
----

A `Not authorized to access topics: [a_messages]` error is returned when trying to push the first message, as expected, so we switch to topic `b_messages`:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic b_messages \
  --producer.config /tmp/team-b-client.properties
Message 1
Message 2
Message 3
----

Producing messages to topic `b_messages` is authorized and successful.

We switch again, but this time to a topic that `team-b-client` can only read from, topic `x_messages`:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --producer.config /tmp/team-b-client.properties
Message 1
----

A `Not authorized to access topics: [x_messages]` error is returned, as expected, so we switch to `team-a-client`:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --producer.config /tmp/team-a-client.properties
Message 1
----

A `Not authorized to access topics: [x_messages]` error is returned again. Though `team-a-client` can write to the `x_messages` topic, it does not have a permission to create a topic if it does not yet exist.

Before `team-a-client` can write to the `x_messages` topic, a admin _power user_ must create it with the correct configuration, such as the number of partitions and replicas.


.Managing Kafka with an authorized admin

Admin user `alice` is created with full access to manage everything on any Kafka cluster.

We can authenticate as `alice` by using `curl` and perform password grant authentication to obtain a refresh token which we can then use to configure the Kafka client.

[source,shell]
----
USERNAME=alice
PASSWORD=alice-password

GRANT_RESPONSE=$(curl -X POST "https://$SSO_HOST/auth/realms/kafka-authz/protocol/openid-connect/token" -H 'Content-Type: application/x-www-form-urlencoded' -d "grant_type=password&username=$USERNAME&password=$PASSWORD&client_id=kafka-cli&scope=offline_access" -s -k)

REFRESH_TOKEN=$(echo $GRANT_RESPONSE | awk -F "refresh_token\":\"" '{printf $2}' | awk -F "\"" '{printf $1}')
----

The refresh token in this case is an offline token which is a long-lived refresh token that does not expire.

A configuration file for `alice` looks like the following:

[source,shell]
----
cat > /tmp/alice.properties << EOF
security.protocol=SASL_SSL
ssl.truststore.location=/tmp/truststore.p12
ssl.truststore.password=$STOREPASS
ssl.truststore.type=PKCS12
sasl.mechanism=OAUTHBEARER
sasl.jaas.config=org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
  oauth.refresh.token="$REFRESH_TOKEN" \
  oauth.client.id="kafka-cli" \
  oauth.ssl.truststore.location="/tmp/truststore.p12" \
  oauth.ssl.truststore.password="$STOREPASS" \
  oauth.ssl.truststore.type="PKCS12" \
  oauth.token.endpoint.uri="https://$SSO_HOST/auth/realms/kafka-authz/protocol/openid-connect/token" ;
sasl.login.callback.handler.class=io.strimzi.kafka.oauth.client.JaasClientOauthLoginCallbackHandler
EOF
----

The `kafka-cli` public client is used for the `oauth.client.id` in the `sasl.jaas.config`.
Since that is a public client it does not require a Secret.
We can use this because we authenticate with a token directly. In this case, the refresh token requests an access token behind the scenes, which is then sent to the Kafka broker for authentication. The refresh token has already been authenticated.


User `alice` has permission to create the `x_messages` topic:

[source,shell]
----
bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/alice.properties \
  --topic x_messages --create --replication-factor 1 --partitions 1
----


User `alice` can list all the topic, whereas `team-a-client` and `team-b-client` can only list topics they have access to:

[source,shell]
----
bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/alice.properties --list
bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/team-a-client.properties --list
bin/kafka-topics.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/team-b-client.properties --list
----

The `Dev Team A`, and `Dev Team B` roles both have `Describe` permission on topics that start with `x_`, but they cannot see the other team's topics as they do not have `Describe` permissions on them.

The `team-a-client` can now successfully produce to the `x_messages` topic:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --producer.config /tmp/team-a-client.properties
Message 1
Message 2
Message 3
----

As expected, `team-b-client` still cannot produce to the `x_messages` topic, and the following operation returns an error:

[source,shell]
----
bin/kafka-console-producer.sh --broker-list my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --producer.config /tmp/team-b-client.properties
Message 4
Message 5
----

However, due to its {keycloak-project-name} settings `team-b-client` can consume messages from the `x_messages` topic:

[source,shell]
----
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --from-beginning --consumer.config /tmp/team-b-client.properties --group x_consumer_group_b
----
Conversely, even though `team-a-client` can write to topic `x_messages`, the following read request returns a `Not authorized to access group: x_consumer_group_a` error:

[source,shell]
----
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --from-beginning --consumer.config /tmp/team-a-client.properties --group x_consumer_group_a
----

A consumer group that begins with `a_` is used in the next read request:

[source,shell]
----
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --from-beginning --consumer.config /tmp/team-a-client.properties --group a_consumer_group_a
----

An error is still returned, but this time it is `Not authorized to access topics: [x_messages]`.

`Dev Team A` has no `Read` access on topics that start with 'x_'.

User `alice` can read from or write to any topic:

[source,shell]
----
bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --topic x_messages \
  --from-beginning --consumer.config /tmp/alice.properties
----

User `alice` can also read the cluster configuration (which in this case is empty):
[source,shell]
----
bin/kafka-configs.sh --bootstrap-server my-cluster-kafka-bootstrap:9093 --command-config /tmp/alice.properties \
  --entity-type brokers --describe --entity-default
----
