// This module is included in:
//
// overview/assembly-kafka-components.adoc

[id="kafka-concepts-components_{context}"]
= Kafka component architecture

[role="_abstract"]
A KRaft-based Kafka cluster consists of broker nodes responsible for message delivery and controller nodes that manage cluster metadata and coordinate clusters.
These roles can be configured using node pools in Strimzi.

Other Kafka components interact with the Kafka cluster for specific tasks.

.Kafka component interaction

image:overview/kafka-concepts-supporting-components.png[Data flows between several Kafka components and the Kafka cluster.]

Kafka Connect:: Kafka Connect is an integration toolkit for streaming data between Kafka brokers and other systems using _connector_ plugins.
Kafka Connect provides a framework for integrating Kafka with an external data source or target, such as a database, for import or export of data using connectors.
Connectors provide the connection configuration needed.
+
--
* A _source_ connector pushes external data into Kafka.
* A _sink_ connector extracts data  out of Kafka
--
+
External data is translated and transformed into the appropriate format.
+
Kafka Connect can be configured to build custom container images with the required connectors.
Kafka MirrorMaker:: Kafka MirrorMaker replicates data between two Kafka clusters, either in the same data center or across different locations.
Kafka Bridge:: Kafka Bridge provides an API for integrating HTTP-based clients with a Kafka cluster.
Kafka Exporter:: Kafka Exporter extracts data for analysis as Prometheus metrics, primarily data relating to offsets, consumer groups, consumer lag and topics. Consumer lag is the delay between the last message written to a partition and the message currently being picked up from that partition by a consumer

Apache ZooKeeper (optional):: Apache ZooKeeper provides a cluster coordination service, storing and tracking the status of brokers and consumers. 
ZooKeeper is also used for controller election. If ZooKeeper is used, the ZooKeeper cluster must be ready before running Kafka. 
However, since the introduction of KRaft, ZooKeeper is no longer required as Kafka nodes handle cluster coordination and control natively.
