// Module included in the following assemblies:
//
// metrics/assembly_metrics-kafka-exporter.adoc

[id='con-metrics-kafka-exporter-lag-{context}']

= Monitoring Consumer lag

Consumer lag indicates the difference in the rate of production and consumption of messages.
Specifically, consumer lag for a given consumer group indicates the delay between the last message in the partition and the message being currently picked up by that consumer.

The lag reflects the position of the consumer offset in relation to the end of the partition log.

.Consumer lag between the producer and consumer offset

image:consumer-lag.png[Consumer lag]

This difference is sometimes referred to as the _delta_ between the producer offset and consumer offset: the read and write positions in the Kafka broker topic partitions.

Suppose a topic streams 100 messages a second. A lag of 1000 messages between the producer offset (the topic partition head) and the last offset the consumer has read means a 10-second delay.

[discrete]
== The importance of monitoring consumer lag

For applications that rely on the processing of (near) real-time data, it is critical to monitor consumer lag to check that it does not become too big.
The greater the lag becomes, the further the process moves from the real-time processing objective.

Consumer lag, for example, might be a result of consuming too much old data that has not been purged, or through unplanned shutdowns.

[discrete]
== Reducing consumer lag

Typical actions to reduce lag include:

* Scaling-up consumer groups by adding new consumers
* Increasing the retention time for a message to remain in a topic
* Adding more disk capacity to increase the message buffer

Actions to reduce consumer lag depend on the underlying infrastructure and the use cases Strimzi is supporting.
For instance, a lagging consumer is less likely to benefit from the broker being able to service a fetch request from its disk cache.
And in certain cases, it might be acceptable to automatically drop messages until a consumer has caught up.
